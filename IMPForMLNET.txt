STAGE 1 — MASTER THE FOUNDATION (Internal Understanding)

==> Step 1: Understand the ML Pipeline Internally

1> What is IDataView really?
	It is central to ML.NET.
	ML.NET dataset container.
	IDataView is a lazy, immutable, column-oriented data abstraction.
	It allows streaming large datasets without loading everything into memory.

	It supports:
		Schema-based column typing
		Deferred execution
		Efficient transformation chaining.

2> Lazy execution
	Performance. Data is processed only when needed
	Memory efficiency
	Supports large datasets
	Optimized execution graph
	Avoids unnecessary computation

3> Column types (Data type of each column) & schema (Structure of dataset)
	Schema = Blueprint of your dataset
	Column types = Data types of each column
	
	ML.NET does NOT directly use C# types internally.
	It uses its own DataView types.

	C# Type		ML.NET Type
	float		Single
	double		Double
	bool		Boolean
	string		Text
	int			Int32
	float[]		Vector<Single>

	Scalar Types = Single value per row:
		Float (Single), Double, Boolean, String (Text), Int32 / Int64
	Vector Types = Used for Array input
		Features column, Images, Embeddings, ONNX inputs
	Special Column Types
		Key Type = Used for classification labels and Encoded label.
				Label: Key<UInt32>
		Vector with Known Size
				Example
				[VectorType(4)]
				public float[] Features { get; set; }

	Schema - You can define schema in 3 ways:
		Method 1 — From C# Class (Most Common)
			ML.NET automatically builds schema from the class.
			E.g = var data = mlContext.Data.LoadFromEnumerable<ModelInput>(dataList);

		Method 2 — From Text File
			Schema is inferred from your class mapping.
			E.g = mlContext.Data.LoadFromTextFile<ModelInput>("data.csv");

		Method 3 — Inspect Schema
			E.g
				var schema = data.Schema;
				foreach (var column in schema)
				{
				    Console.WriteLine($"{column.Name} - {column.Type}");
				}

	Why Schema is Important
		Because ML.NET is:
			Lazy-evaluated, Strongly typed, Pipeline-based

		If your schema does not match:
			Model input, ONNX expected input, Trainer requirements

		You’ll get runtime errors.

4> Why transformations are chained
	In ML.NET, transformations are chained because ML.NET uses a pipeline architecture.
	Instead of modifying data step-by-step manually, you build a processing pipeline where:
		Each transformation takes the output of the previous one and passes it forward.
	
	There are 4 main reasons:
		1. Data Flows Step-by-Step (Like an Assembly Line)
			Machine learning requires multiple preprocessing steps:
			Raw Data → Clean → Encode → Combine → Normalize → Train
			Each step depends on the previous one.

			Step1.Output → Step2.Input → Step3.Input → Trainer

		2. ML.NET Uses Lazy Evaluation
			ML.NET does not process data immediately.
			It builds a transformation graph and executes it only when needed (like during .Fit()).
			Chaining creates a single executable pipeline.
		
		3. Reproducibility
			When you chain transformations:
			var pipeline = step1
               .Append(step2)
               .Append(step3)
               .Append(trainer);
			You can:
				Save the model, Load it later, Use it in production

		4. Cleaner & Modular Code
			Instead of:
				var step1 = ...
				var step2 = ...
				var step3 = ...

			You write one pipeline that describes the entire workflow.

5> Difference between Estimator and Transformer?
	Estimator = blueprint
	Transformer = trained result

	Estimator is stateless.
	Transformer contains learned parameters.

6> What happens internally when you call Fit()?
	Schema validation
	Transformation fitting
	Trainer optimization (gradient descent / tree building)
	Model parameters stored in Transformer

7> How does ML.NET handle schema mismatches?
	It throws runtime schema validation errors based on expected column types and names.
	Best practice:
		Keep strong typed models
		Save and reuse schema

==============================================
==============================================

STAGE 2 — UNDERSTAND THE MATH (Critical for Senior Level)
	You cannot go deep in ML without math intuition.

==> Step 2: Logistic Regression Internals
	Used in spam detection. (Detect the spam message from csv, I already implemented)

	Learn:
	Why output between 0 and 1
		Log-loss (Penalizes wrong confident predictions heavily.)
		Decision threshold

1> Why sigmoid?
	To convert linear output into probability.
	Optimized using log-loss
	Uses gradient descent

2> What causes overfitting in logistic regression?
	Too many features without regularization.

==> Step 3: Regression Loss Understanding
	Used in home price model.
	Learn:
		Why square error?
			To remove negative sign.
				Actual 50 and Predicted 60, Error -10.
			To Punish Big Mistakes More
				Error = 2 → 2² = 4
				Error = 10 → 10² = 100

				Big mistakes become MUCH bigger.
				So the model tries hard to avoid big errors.
			Easy for Computer to Learn
				Squared error makes the graph smooth like a bowl.
				That makes it easy for algorithms (like gradient descent) to find the best solution.

			We use squared error because:
				It removes negative signs
				It punishes big mistakes more
				It helps the model learn easily

		Why RMSE (Root Mean Squared Error) interpretable?
			RMSE is in the same unit as your target value.
			It is in the same unit as actual values
			It tells you how much your prediction is wrong on average
			It is easy to explain in real life
			RMSE tells you the average prediction mistake in the same unit as your data.

			E.g = Suppose you are predicting house price in dollars.
				RMSE = 5000
				On average, your prediction is wrong by about $5000

			Why Not Use MSE?
				MSE is: Error²
				If MSE = 25,000,000
				Can you understand that? Not really.
				Because:
					It is squared
					It is not in dollars
					It is in dollars² (which is confusing)
			
		R² meaning
			R² is only for regression, not classification.
			High R² does not always mean a good model (can overfit).
			It does not detect:
				Overfitting, Bias, Whether predictions are practically useful
			Always check RMSE and MAE alongside R².

			| R² Value      | Meaning                                 |
			| ------------- | --------------------------------------- |
			| **1.0**       | Perfect prediction                      |
			| **0.9+**      | Excellent fit                           |
			| **0.7 – 0.9** | Good fit                                |
			| **0.5 – 0.7** | Moderate fit                            |
			| **0**         | Model explains nothing                  |
			| **< 0**       | Model is worse than predicting the mean |


3> When to use MAE over MSE?
	When you want robustness to outliers.
		MAE = Mean Absolute Error
			MAE more robust to outliers
			It takes the absolute value of error.
			It tells you the average mistake size.
			Easy to understand.
			Treats all errors equally.
			E.g = MAE = 5 (Means, Your model is wrong by about 5 units on average.)

		MSE = Mean Squared Error
			Average of the squared differences between actual and predicted values.
			
			Why square?
				Penalizes large errors more heavily.
				Useful when large mistakes are very bad.
			Downside
				Unit becomes squared (e.g., dollars²).	

		RMSE = Mean Root Mean Squared Error
			Square root of MSE.
			It squares errors first, then takes square root.
			Also tells average error but It punishes big mistakes more.
			E.g = 2, 2, 2, 10
				MAE = Adds them normally → average = smaller impact of 10
				RMSE = Squares them, Now 10 becomes 100 So RMSE becomes much bigger.

			Why use RMSE?
				Same unit as original data.
				Still penalizes large errors more than MAE.
				Most commonly used regression metric.

		| MAE                       | RMSE                                |
		| ------------------------- | ----------------------------------- |
		| Treats all errors equally | Punishes big errors more            |
		| Simple average mistake    | Sensitive to large mistakes         |
		| Good when outliers exist  | Good when big mistakes are very bad |

		| Metric | Penalizes Large Errors? | Unit Same as Target? | Sensitivity |
		| ------ | ----------------------- | -------------------- | ----------- |
		| MAE    | ❌ No                    | ✅ Yes                | Low         |
		| MSE    | ✅ Yes (strong)          | ❌ No                 | High        |
		| RMSE   | ✅ Yes                   | ✅ Yes                | High        |

	Use MAE → when all errors are equally important
	Use RMSE → when large errors are very bad
	Use MSE → mainly for optimization/training

	var metrics = mlContext.Regression.Evaluate(predictions);
		Console.WriteLine($"MAE: {metrics.MeanAbsoluteError}");
		Console.WriteLine($"MSE: {metrics.MeanSquaredError}");
		Console.WriteLine($"RMSE: {metrics.RootMeanSquaredError}");

4> What does R² = 0.85 mean?
	Model explains 85% variance. (As per above table of R²)
	Percentage of variance explained by model.
	0.8 = explains 80% variability.

5> What is cross-validation?
	Splitting dataset into multiple folds to reduce overfitting and evaluate robustness.

======================================================
======================================================
STAGE 3 — TREE & BOOSTING MODELS (Very Important)

ML.NET supports:
	FastTree
	LightGBM

Understand:
	Gini impurity
	Gradient boosting
	Ensemble learning

Exercise
	Train
		Logistic Regression
		FastTree
	Compare
		Accuracy
		Training time
		Feature importance

1> Why do tree models often outperform linear models?
	They capture nonlinear relationships.

2> What is Gradient Boosting?
	Sequentially fixing previous errors.
	Sequential trees trained to correct previous residual errors.
	Used in = FastTree, LightGBM

3> What is bias–variance tradeoff?
	High bias → underfitting
	High variance → overfitting
	Goal: balance both

4> When would you use SDCA instead of FastTree?
	Large sparse data
	Linear relationships
	Text classification
	High dimensionality

======================================================
======================================================
STAGE 4 — FEATURE ENGINEERING (Where Real ML Skill Lives)

Text Processing Deep Dive
	Instead of default FeaturizeText():
		Experiment with:
			N-grams, Character grams, Stop word removal, TF-IDF

Improve spam detection accuracy by:
	Adding char-level features
	Removing rare words

When should you normalize features?
	For gradient-based models:
		SDCA
		Logistic Regression
		Linear Regression
	Not required for tree models.

Why normalize features?
	For gradient-based models to converge faster.

One-hot encoding vs hashing?
	One-hot:
		Clear mapping
		High dimensional

	Hashing:
		Fixed size
		Possible collisions

What is one-hot encoding problem?
	High dimensionality explosion.

What is TF-IDF?
	Term Frequency × Inverse Document Frequency.
	Weights important words higher.

How do you detect feature importance?
	Permutation Feature Importance.
	It measures performance drop when a feature is shuffled.
========================================================
========================================================
STAGE 5 — MODEL EVALUATION MASTERY

Classification Metrics
	Understand deeply:
		Precision, Recall, F1, ROC curve, Confusion matrix

	Exercise
		Create imbalanced dataset.
			Observe: Accuracy misleading, Recall critical

Why accuracy is bad for imbalanced data?
	Model can predict majority class and still look good.
	If 95% are non-spam, predicting always non-spam gives 95% accuracy.

	Better metrics:
		Precision, Recall, F1, ROC-AUC

What is ROC-AUC?
	Measures model’s ability to separate classes across thresholds.
	Closer to 1 → better separability.

========================================================
========================================================
STAGE 6 — HYPERPARAMETER TUNING
	Now move from default training to controlled training.
	E.g
		new FastTreeBinaryTrainer.Options
		{
		    NumberOfLeaves = 20,
		    NumberOfTrees = 200,
		    LearningRate = 0.2
		}

	Exercise
		Change: NumberOfTrees, LearningRate
	Track performance changes.

What happens if learning rate too high?
	Overshooting → unstable training.

========================================================
========================================================
STAGE 7 — EXPLAINABILITY
	Use:
		Permutation Feature Importance
	Ask:
		Which feature matters most?
		Why did model predict spam?

How do you explain ML model to business?
	Feature importance + probability interpretation.

========================================================
========================================================
STAGE 8 — DEEP LEARNING WITH ML.NET
	Now go advanced.
	ML.NET allows:
		TensorFlow model scoring
		ONNX model scoring
	Build
		Image classifier
		Pre-trained BERT inference
	Exercise
		Export model to ONNX.
		Load it back.
		Compare performance.
========================================================
========================================================
STAGE 9 — PRODUCTION ML (Where Senior Devs Shine)
	Learn
		PredictionEnginePool
		Thread safety
		Model caching
		Retraining pipeline
		Model versioning

	Build
		ASP.NET Core ML API
		Background retraining service

	Is PredictionEngine thread-safe?
		No
		PredictionEnginePool in ASP.NET Core.

	Solution?
		PredictionEnginePool.
		
	How to optimize large dataset training?
		Use streaming IDataView
		Use caching only when needed
		Use LightGBM for large data
		Use multi-threaded trainers

	When to use Cache() in pipeline?
		Dataset reused multiple times
		Cross-validation
		Expensive transformations
	Avoid for very large datasets.

	How do you version ML models?
		Store model with version tag
		Use model registry
		Keep metadata (training data version, hyperparameters)

	What is model drift?
		When production data distribution changes from training data.
		Solution
			Monitor metrics
			Retrain periodically

	How do you design production ML.NET architecture?
		Architecture includes:
			Training service
			Model storage
			Prediction API
			Monitoring system
			Retraining pipeline

		Tech stack example:
			ASP.NET Core API
			Background worker
			Model persistence (.zip)
			Logging system
			Scheduled retraining

	Why do tree models not require normalization?
		Because trees split based on thresholds, not gradient magnitude.
		

========================================================
========================================================
STAGE 10 — READ SOURCE CODE
	ML.NET is open-source under Microsoft
	Read
		FastTree source
		SDCA trainer
		Pipeline implementation

=======================================================
=======================================================

6-MONTH SERIOUS PLAN
Month 1:
	Deep math
	Logistic + regression theory

Month 2:
	Trees + boosting
	Hyperparameter tuning

Month 3:
	Feature engineering mastery

Month 4:
	Explainability + evaluation

Month 5:
	Deep learning integration (ONNX, TensorFlow)

Month 6:
	Production ML system design

=========================================================
=========================================================
FINAL CHALLENGE FOR YOU
	Build a complete ML system:
		Train model
		Save model
		Deploy API
		Log predictions
		Monitor drift
		Auto retrain
		Version models